{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01bb4211",
   "metadata": {},
   "source": [
    "### 1. Two‑Stage Detectors (Phát hiện hai giai đoạn)\n",
    "1. **R‑CNN (Region‑based CNN)**  \n",
    "   - R‑CNN: trích xuất đề xuất vùng (region proposals) qua Selective Search, rồi áp dụng CNN riêng cho từng vùng.  \n",
    "   - Fast R‑CNN: gộp chung tính toán CNN cho toàn ảnh, sau đó trích đặc trưng cho mỗi đề xuất vùng bằng ROI Pooling.  \n",
    "   - Faster R‑CNN: thay thế Selective Search bằng Region Proposal Network (RPN) tích hợp ngay trong mạng, tăng tốc đáng kể.  \n",
    "   - Mask R‑CNN: mở rộng Faster R‑CNN thêm nhánh phân đoạn (segmentation) cho mỗi vùng, cho kết quả mask pixel-wise.\n",
    "\n",
    "**Ưu điểm:** độ chính xác rất cao, đặc biệt với các vật thể nhỏ hoặc phức tạp.  \n",
    "**Nhược điểm:** tốc độ chậm hơn so với one‑stage.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. One‑Stage Detectors (Phát hiện một giai đoạn)\n",
    "1. **YOLO (You Only Look Once)**  \n",
    "   - YOLOv1 → v2 (YOLO9000) → v3 → v4 → v5 → v7, v8…: chia ảnh thành grid, mỗi ô dự đoán thẳng tọa độ hộp và xác suất lớp.  \n",
    "2. **SSD (Single Shot MultiBox Detector)**  \n",
    "   - Sử dụng nhiều feature maps ở các độ phân giải khác nhau để dự đoán hộp ở nhiều tỉ lệ khác nhau.  \n",
    "3. **RetinaNet**  \n",
    "   - Giới thiệu hàm mất mát Focal Loss để giải quyết vấn đề mất cân bằng dương‑âm giữa các anchor.\n",
    "\n",
    "**Ưu điểm:** tốc độ phát hiện nhanh, phù hợp ứng dụng thời gian thực.  \n",
    "**Nhược điểm:** thường kém chính xác hơn two‑stage với những vật thể nhỏ, hoặc nền phức tạp.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Anchor‑Free & Keypoint‑Based Detectors (Không dùng anchor)\n",
    "1. **CornerNet**  \n",
    "   - Dự đoán cặp góc (top‑left, bottom‑right) của mỗi hộp.  \n",
    "2. **CenterNet**  \n",
    "   - Dự đoán điểm tâm (object center) và kích thước hộp.  \n",
    "3. **FCOS (Fully Convolutional One‑Stage Object Detection)**  \n",
    "   - Từng pixel trên feature map dự đoán trực tiếp offset đến hộp chứa vật thể (no anchors).  \n",
    "\n",
    "**Ưu điểm:** loại bỏ các siêu tham số anchor (tỉ lệ, kích thước), đơn giản hóa thiết kế mạng.  \n",
    "**Nhược điểm:** độ chính xác có thể kém hơn anchor‑based trong một số trường hợp.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Transformer‑Based Detectors\n",
    "1. **DETR (Detection Transformer)**  \n",
    "   - Lần đầu tiên ứng dụng kiến trúc Transformer cho object detection, dùng cơ chế attention giữa các “object query” và feature map.  \n",
    "2. **Deformable DETR**  \n",
    "   - Cải tiến để tăng tốc hội tụ và hiệu suất với attention “deformable” chọn lọc vị trí quan trọng.  \n",
    "\n",
    "**Ưu điểm:** khung thiết kế thống nhất, ít cần tinh chỉnh siêu tham số.  \n",
    "**Nhược điểm:** thời gian huấn luyện lâu hơn, cần nhiều dữ liệu.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Các biến thể và hướng mở rộng\n",
    "- **Tích hợp phân đoạn (Instance Segmentation):** Mask R‑CNN, YOLACT,…  \n",
    "- **Phát hiện 3D (3D Object Detection):** PointRCNN, PV‑RCNN, VoteNet…  \n",
    "- **Phát hiện đa chế độ (Multi‑Modal):** LiDAR + RGB, Radar + Camera, v.v.  \n",
    "\n",
    "---\n",
    "\n",
    "**Tóm lại**, khi chọn thuật toán object detection theo mạng nơ‑ron, bạn cần cân nhắc giữa:  \n",
    "- **Độ chính xác** (accuracy) vs. **Tốc độ** (speed)  \n",
    "- **Kích thước vật thể** (small vs. large)  \n",
    "- **Mức độ phức tạp** (cần anchor‑tuning hay không)  \n",
    "- **Khả năng mở rộng** (sang segmentation, 3D, multi‑modal…)\n",
    "\n",
    "Nếu bạn có thêm yêu cầu cụ thể (ví dụ: thời gian thực, thiết bị giới hạn tài nguyên, hoặc kiểu vật thể cần phát hiện), mình có thể gợi ý chi tiết hơn về mô hình phù hợp!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b990412",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
